{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "66e479f2-fbce-4a60-a139-36e7478fc7f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01d1f153-d63a-4a4e-aa0f-1a401d942d92",
   "metadata": {},
   "source": [
    "# introdduction to tensors\n",
    "\n",
    "### Creating scalars\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b1462ecb-05e0-4c1a-82c1-51983899e540",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(7)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#scalar\n",
    "\n",
    "scalar= torch.tensor(7)\n",
    "scalar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0b7ff2b9-0789-47cb-bf05-deed0e673bef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([7, 7])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# vector\n",
    "\n",
    "vector= torch.tensor([7, 7])\n",
    "vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2f69393d-cc6a-4bf2-b480-856882c93a74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[7, 1],\n",
       "        [5, 3]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# matrix\n",
    "\n",
    "matrix= torch.tensor([[7, 1], \n",
    "                     [5, 3]])\n",
    "\n",
    "matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3f820edf-1e84-440a-bf85-d78b69aa7e61",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[3, 5],\n",
       "          [4, 6],\n",
       "          [1, 9]]]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TENSOR= torch.tensor([[[[3, 5], \n",
    "                       [4, 6],\n",
    "                       [1, 9]]]])\n",
    "\n",
    "TENSOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "85eb612f-17ee-4a79-a79c-de8f025d77c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dimension of the variable \"scalar\" is 0.\n",
      "The dimension of the variable \"vector\" is 1.\n",
      "The dimension of the variable \"matrix\" is 2.\n",
      "The dimension of the variable \"TENSOR\" is 4.\n"
     ]
    }
   ],
   "source": [
    "# To check the dimension of a tensor we use `torch.ndim`\n",
    "\n",
    "print(f'The dimension of the variable \"scalar\" is {scalar.ndim}.\\nThe dimension of the variable \"vector\" is {vector.ndim}.\\nThe dimension of the variable \"matrix\" is {matrix.ndim}.\\\n",
    "\\nThe dimension of the variable \"TENSOR\" is {TENSOR.ndim}.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "56e3579d-81da-4bfe-b352-81190b66dde5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of the variable \"scalar\" is torch.Size([]).\n",
      "The shape of the variable \"vector\" is torch.Size([2]).\n",
      "The shape of the variable \"matrix\" is torch.Size([2, 2]).\n",
      "The shape of the variable \"TENSOR\" is torch.Size([1, 1, 3, 2]).\n"
     ]
    }
   ],
   "source": [
    "# to check the shapes of the above\n",
    "\n",
    "print(f'The shape of the variable \"scalar\" is {scalar.shape}.\\nThe shape of the variable \"vector\" is {vector.shape}.\\nThe shape of the variable \"matrix\" is {matrix.shape}.\\\n",
    "\\nThe shape of the variable \"TENSOR\" is {TENSOR.shape}.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bae0e387-c76e-48b0-a05e-0d9343ab77b2",
   "metadata": {},
   "source": [
    "<h3>Summary of types of tensor objects</h3>\n",
    "\n",
    "| Name   | What is it?                                     | Number of Dimensions | Variable Nomenclature |\n",
    "| ------: | -----------------------------------------------: | --------------------: | ---------------------: |\n",
    "| Scaler | A single number, representing only magnitude     | 0                    | Lower (a)             |\n",
    "| Vector | A number with direction, can have many other numbers | 1 | lower (y) |\n",
    "| Matrix | A 2 dimensional array of numbers | 2 | Upper (Q) |\n",
    "| Tensor | A n-dimensional array of numbers | Can be any number: 0 = scalar, 1 = vector, 2= matrix | Upper (X) |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0afa0ba5-ed95-4d23-a0af-2162946c517b",
   "metadata": {},
   "source": [
    "### Torch object xtics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c9cb41c8-7254-438f-9128-a50291293f59",
   "metadata": {},
   "outputs": [],
   "source": [
    "TENSOR= torch.tensor([[[1,4], [5, 6]], \n",
    "              [[2, 7], [3, 5]],\n",
    "              [[7, 9], [2, 9]]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "bec472ae-3628-4b6f-b8b6-a97908ba631f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 2, 2])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TENSOR.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "09e1dc53-ba18-4589-a506-79a6d7753718",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TENSOR.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b9300334-84a3-4116-a08d-dd3601f46970",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.int64"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TENSOR.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8319a75-272d-413a-890f-f58d55a9ca71",
   "metadata": {},
   "source": [
    "### Random Tensors\n",
    "\n",
    "Why Random  Tensors?\n",
    "\n",
    "this is because machine learning models usually start training with a large set of random numbers and keep adjusting weights at each epoch until it achieves its goal or completes the number of epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "aa06e435-bb74-4cd5-864b-0b90fe144b51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.4779, 0.2687, 0.6532, 0.1329],\n",
       "        [0.1303, 0.1637, 0.7457, 0.9641],\n",
       "        [0.6145, 0.3679, 0.5671, 0.7304]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating a `Random Tensors` of shape (3, 4)\n",
    "\n",
    "r_tensor= torch.rand(3, 4)\n",
    "r_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8e392502-8304-45cf-9eee-5c2015816704",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([224, 224, 3]), 3)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a random tensor with similar shape to an image tensor. the shape of an image tensor is given as (height, width, channels)\n",
    "# example a 255 pixels square color image will be (224, 224, 3) as there are 3 color channels for thr RGB\n",
    "\n",
    "rand_image= torch.rand(224, 224, 3)\n",
    "rand_image.shape, rand_image.ndim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acb06de2-980d-42eb-878c-3cc02efdb6c5",
   "metadata": {},
   "source": [
    "### Tensors of Zeros and Ones\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4c79a9e1-53a3-4502-821a-60c182e3d85a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a tensor of zeros\n",
    "zero_tensor= torch.zeros(3, 4)\n",
    "zero_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "12984ab9-e2da-4f5e-bba4-abf600f5ffaf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.]])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a tensor of ones\n",
    "\n",
    "one_tensor= torch.ones(3, 4)\n",
    "one_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9d6555b-9ffb-4bf6-8622-22542137940e",
   "metadata": {},
   "source": [
    "### Creating a range of tensors and tensors-like\n",
    "\n",
    "torch.range(start, end, step) the `end` is exclusive and the start is inclusive. however range is to be depreccated in future versions and thus a better fix will be torch.arange(start, end, step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "5834e984-5b10-47df-938f-84ba16224edb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a torch range\n",
    "one_to_ten= torch.arange(1, 11, 1)\n",
    "one_to_ten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "194261b4-7611-4f64-a8cb-61fcda074b0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.4325, 0.5556, 0.9302, 0.3229],\n",
       "        [0.8370, 0.7735, 0.6428, 0.9074],\n",
       "        [0.1423, 0.2514, 0.2625, 0.6721]])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To create a tensor like another, we use the rand, zero or ones_like the tensor we are trying to copy\n",
    "\n",
    "torch.rand_like(one_tensor) # created a random tensor like one_tensor created above"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1970c669-0345-4356-a623-781ff92f9b2c",
   "metadata": {},
   "source": [
    "### Tensor Datatypes\n",
    "\n",
    "when creating a tensor there are 3 important parameters, are \n",
    "\n",
    "| Tensor parameter | Action | \n",
    "| :---------------- | :-------|\n",
    "| dtype | defaults to `None`. Used to set the datatype for the objects created eg. torch.float32, torch.float64, torch.float16/torch.half, torch.bfloat16 : https://pytorch.org/docs/stable/tensor_attributes.html |\n",
    "| device | default to `None`. This sets the device on which the tensor will be created. If utilizing a GPU using the passing the type argument set the device |\n",
    "| requires_grad | defaults to `False`. This defines whether gradients should be tracked on operations with this tensor. |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "0d63ffbd-43b1-448a-b198-b391f63e9d5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 2., 3.],\n",
      "        [4., 5., 6.]]) torch.float32 \n",
      "\n",
      "tensor([[1., 2., 3.],\n",
      "        [4., 5., 6.]], dtype=torch.float16)\n"
     ]
    }
   ],
   "source": [
    "# integers\n",
    "\n",
    "float_32= torch.tensor([[1,2,3],\n",
    "                        [4,5,6]],\n",
    "                       dtype= torch.float32)\n",
    "print(float_32, float_32.dtype, '\\n')\n",
    "\n",
    "# to change the data type of a tensor, we use the type method\n",
    "\n",
    "float_16= float_32.type(torch.float16)\n",
    "print(float_16)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da6bf2f7-11fe-4b74-bf2d-19f7e5bdfef3",
   "metadata": {},
   "source": [
    "## Note\n",
    "there are 3 main error we will run into with PyTorch and deep learning. These are:\n",
    "<ol>\n",
    "    <li>Tensor not right datatype</li>\n",
    "    <li>Tensor not right shape</li>\n",
    "    <li>Tensor not on right device</li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c99d7c36-a2e0-4053-8bfe-131c95613603",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
