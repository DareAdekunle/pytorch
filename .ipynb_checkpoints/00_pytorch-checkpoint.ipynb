{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "66e479f2-fbce-4a60-a139-36e7478fc7f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01d1f153-d63a-4a4e-aa0f-1a401d942d92",
   "metadata": {},
   "source": [
    "# introdduction to tensors\n",
    "\n",
    "### Creating scalars\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b1462ecb-05e0-4c1a-82c1-51983899e540",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(7)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#scalar\n",
    "\n",
    "scalar= torch.tensor(7)\n",
    "scalar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0b7ff2b9-0789-47cb-bf05-deed0e673bef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([7, 7])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# vector\n",
    "\n",
    "vector= torch.tensor([7, 7])\n",
    "vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2f69393d-cc6a-4bf2-b480-856882c93a74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[7, 1],\n",
       "        [5, 3]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# matrix\n",
    "\n",
    "matrix= torch.tensor([[7, 1], \n",
    "                     [5, 3]])\n",
    "\n",
    "matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3f820edf-1e84-440a-bf85-d78b69aa7e61",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[3, 5],\n",
       "          [4, 6],\n",
       "          [1, 9]]]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TENSOR= torch.tensor([[[[3, 5], \n",
    "                       [4, 6],\n",
    "                       [1, 9]]]])\n",
    "\n",
    "TENSOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "85eb612f-17ee-4a79-a79c-de8f025d77c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dimension of the variable \"scalar\" is 0.\n",
      "The dimension of the variable \"vector\" is 1.\n",
      "The dimension of the variable \"matrix\" is 2.\n",
      "The dimension of the variable \"TENSOR\" is 4.\n"
     ]
    }
   ],
   "source": [
    "# To check the dimension of a tensor we use `torch.ndim`\n",
    "\n",
    "print(f'The dimension of the variable \"scalar\" is {scalar.ndim}.\\nThe dimension of the variable \"vector\" is {vector.ndim}.\\nThe dimension of the variable \"matrix\" is {matrix.ndim}.\\\n",
    "\\nThe dimension of the variable \"TENSOR\" is {TENSOR.ndim}.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "56e3579d-81da-4bfe-b352-81190b66dde5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of the variable \"scalar\" is torch.Size([]).\n",
      "The shape of the variable \"vector\" is torch.Size([2]).\n",
      "The shape of the variable \"matrix\" is torch.Size([2, 2]).\n",
      "The shape of the variable \"TENSOR\" is torch.Size([1, 1, 3, 2]).\n"
     ]
    }
   ],
   "source": [
    "# to check the shapes of the above\n",
    "\n",
    "print(f'The shape of the variable \"scalar\" is {scalar.shape}.\\nThe shape of the variable \"vector\" is {vector.shape}.\\nThe shape of the variable \"matrix\" is {matrix.shape}.\\\n",
    "\\nThe shape of the variable \"TENSOR\" is {TENSOR.shape}.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bae0e387-c76e-48b0-a05e-0d9343ab77b2",
   "metadata": {},
   "source": [
    "<h3>Summary of types of tensor objects</h3>\n",
    "\n",
    "| Name   | What is it?                                     | Number of Dimensions | Variable Nomenclature |\n",
    "| ------: | -----------------------------------------------: | --------------------: | ---------------------: |\n",
    "| Scaler | A single number, representing only magnitude     | 0                    | Lower (a)             |\n",
    "| Vector | A number with direction, can have many other numbers | 1 | lower (y) |\n",
    "| Matrix | A 2 dimensional array of numbers | 2 | Upper (Q) |\n",
    "| Tensor | A n-dimensional array of numbers | Can be any number: 0 = scalar, 1 = vector, 2= matrix | Upper (X) |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0afa0ba5-ed95-4d23-a0af-2162946c517b",
   "metadata": {},
   "source": [
    "### Torch object xtics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c9cb41c8-7254-438f-9128-a50291293f59",
   "metadata": {},
   "outputs": [],
   "source": [
    "TENSOR= torch.tensor([[[1,4], [5, 6]], \n",
    "              [[2, 7], [3, 5]],\n",
    "              [[7, 9], [2, 9]]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bec472ae-3628-4b6f-b8b6-a97908ba631f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 2, 2])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TENSOR.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "09e1dc53-ba18-4589-a506-79a6d7753718",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TENSOR.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b9300334-84a3-4116-a08d-dd3601f46970",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TENSOR.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8319a75-272d-413a-890f-f58d55a9ca71",
   "metadata": {},
   "source": [
    "### Random Tensors\n",
    "\n",
    "Why Random  Tensors?\n",
    "\n",
    "this is because machine learning models usually start training with a large set of random numbers and keep adjusting weights at each epoch until it achieves its goal or completes the number of epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "aa06e435-bb74-4cd5-864b-0b90fe144b51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.8971, 0.7046, 0.8100, 0.3257],\n",
       "        [0.1715, 0.0914, 0.7341, 0.8216],\n",
       "        [0.9858, 0.0982, 0.1723, 0.8095]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating a `Random Tensors` of shape (3, 4)\n",
    "\n",
    "r_tensor= torch.rand(3, 4)\n",
    "r_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8e392502-8304-45cf-9eee-5c2015816704",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([224, 224, 3]), 3)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a random tensor with similar shape to an image tensor. the shape of an image tensor is given as (height, width, channels)\n",
    "# example a 255 pixels square color image will be (224, 224, 3) as there are 3 color channels for thr RGB\n",
    "\n",
    "rand_image= torch.rand(224, 224, 3)\n",
    "rand_image.shape, rand_image.ndim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acb06de2-980d-42eb-878c-3cc02efdb6c5",
   "metadata": {},
   "source": [
    "### Tensors of Zeros and Ones\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4c79a9e1-53a3-4502-821a-60c182e3d85a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a tensor of zeros\n",
    "zero_tensor= torch.zeros(3, 4)\n",
    "zero_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "12984ab9-e2da-4f5e-bba4-abf600f5ffaf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a tensor of ones\n",
    "\n",
    "one_tensor= torch.ones(3, 4)\n",
    "one_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9d6555b-9ffb-4bf6-8622-22542137940e",
   "metadata": {},
   "source": [
    "### Creating a range of tensors and tensors-like\n",
    "\n",
    "torch.range(start, end, step) the `end` is exclusive and the start is inclusive. however range is to be depreccated in future versions and thus a better fix will be torch.arange(start, end, step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5834e984-5b10-47df-938f-84ba16224edb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a torch range\n",
    "one_to_ten= torch.arange(1, 11, 1)\n",
    "one_to_ten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "194261b4-7611-4f64-a8cb-61fcda074b0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.3592, 0.4422, 0.8915, 0.1732],\n",
       "        [0.8425, 0.1850, 0.4756, 0.9808],\n",
       "        [0.9310, 0.5241, 0.9084, 0.5102]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To create a tensor like another, we use the rand, zero or ones_like the tensor we are trying to copy\n",
    "\n",
    "torch.rand_like(one_tensor) # created a random tensor like one_tensor created above"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1970c669-0345-4356-a623-781ff92f9b2c",
   "metadata": {},
   "source": [
    "### Tensor Datatypes\n",
    "\n",
    "when creating a tensor there are 3 important parameters, are \n",
    "\n",
    "| Tensor parameter | Action | \n",
    "| :---------------- | :-------|\n",
    "| dtype | defaults to `None`. Used to set the datatype for the objects created eg. torch.float32, torch.float64, torch.float16/torch.half, torch.bfloat16 : https://pytorch.org/docs/stable/tensor_attributes.html |\n",
    "| device | default to `None`. This sets the device on which the tensor will be created. If utilizing a GPU using the passing the type argument set the device |\n",
    "| requires_grad | defaults to `False`. This defines whether gradients should be tracked on operations with this tensor. |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0d63ffbd-43b1-448a-b198-b391f63e9d5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 2., 3.],\n",
      "        [4., 5., 6.]]) torch.float32 \n",
      "\n",
      "tensor([[1., 2., 3.],\n",
      "        [4., 5., 6.]], dtype=torch.float16)\n"
     ]
    }
   ],
   "source": [
    "# integers\n",
    "\n",
    "float_32= torch.tensor([[1,2,3],\n",
    "                        [4,5,6]],\n",
    "                       dtype= torch.float32)\n",
    "print(float_32, float_32.dtype, '\\n')\n",
    "\n",
    "# to change the data type of a tensor, we use the type method\n",
    "\n",
    "float_16= float_32.type(torch.float16)\n",
    "print(float_16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4605f59-228f-4118-88e7-9c3826224cf9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "da6bf2f7-11fe-4b74-bf2d-19f7e5bdfef3",
   "metadata": {},
   "source": [
    "## Note\n",
    "there are 3 main error we will run into with PyTorch and deep learning. These are:\n",
    "<ol>\n",
    "    <li>Tensor not right datatype</li>\n",
    "    <li>Tensor not right shape</li>\n",
    "    <li>Tensor not on right device</li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1c6c860-8348-42e1-ba5a-5e303bcab2bd",
   "metadata": {},
   "source": [
    "## Getting information from Tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "859b4167-5ba8-4d04-a1c5-7dbfc19524d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a random tensor\n",
    "\n",
    "tensor= torch.rand([3, 5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6282196e-1fae-412b-b348-9b7cbacba422",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 5]) \n",
      " torch.Size([3, 5])\n"
     ]
    }
   ],
   "source": [
    "# to check the shape of a tensor, we use tensor.shape or .size()\n",
    "\n",
    "print(tensor.shape, '\\n', tensor.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "569e5495-422c-42de-809f-63c360d79ba2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# to chect the data type of a tensor we use the attribute of a tensor called dtype\n",
    "\n",
    "tensor.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ce58d02a-e719-4788-a4b1-cd3141710856",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# to check the device a tensor is on, we use the .device attributes\n",
    "\n",
    "tensor.device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64966aae-5417-4c8c-8a1b-95eaa6cb0a45",
   "metadata": {},
   "source": [
    "## Manipulating Tensors\n",
    "\n",
    "Tensor operation include:\n",
    "1. additions\n",
    "2. subtraction\n",
    "3. multiplication (element-wise)\n",
    "4. division\n",
    "5. matrix multiplication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f2ae7126-92c3-4af0-83e3-9d71c238d8cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([11, 12, 13])\n",
      "tensor([-9, -8, -7])\n",
      "tensor([10, 20, 30])\n",
      "tensor([0.1000, 0.2000, 0.3000])\n"
     ]
    }
   ],
   "source": [
    "# addition\n",
    "\n",
    "tensor_a= torch.tensor([1, 2, 3])\n",
    "\n",
    "print(tensor_a + 10)\n",
    "\n",
    "# subtraction\n",
    "\n",
    "print(tensor_a - 10)\n",
    "\n",
    "# multiplication\n",
    "\n",
    "print(tensor_a * 10)\n",
    "\n",
    "# division\n",
    "\n",
    "print(tensor_a / 10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99db691a-f654-4459-b9aa-fd5d4493e074",
   "metadata": {},
   "source": [
    "### matrix multiplication\n",
    "\n",
    "there are 2 types of multiplication in torch\n",
    "\n",
    "1. element-wise\n",
    "2. Dot product multiplication (matrix multiplication shape (m, n) * (n, k) and the resulting matrix is the dimension of the outer matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "103e16f5-73fe-4c90-a441-05eff78d9f77",
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor= torch.tensor([1, 2, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d1406894-0971-4fef-9038-d908189b5c69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 2, 3])\n",
      "CPU times: user 1.95 ms, sys: 2.89 ms, total: 4.84 ms\n",
      "Wall time: 4.28 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "value= 0\n",
    "for i in range(len(tensor)):\n",
    "    value+= tensor[i] + tensor[i]\n",
    "\n",
    "print(tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7de74d82-7d9d-440a-8915-cf00ed5518f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 873 µs, sys: 2.39 ms, total: 3.26 ms\n",
      "Wall time: 3.83 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(14)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "torch.matmul(tensor, tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "037b4eb2-003a-4465-b125-2892b29ee778",
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor_a= torch.tensor([[3, 2], \n",
    "               [4, 5],\n",
    "               [6, 7]])\n",
    "\n",
    "tensor_b= torch.tensor([[1, 2],\n",
    "                        [3, 4], \n",
    "                        [5, 6]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "05b5f860-d004-4e4f-9917-df322e09fbda",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (3x2 and 3x2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[47], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmatmul\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensor_a\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtensor_b\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (3x2 and 3x2)"
     ]
    }
   ],
   "source": [
    "torch.matmul(tensor_a, tensor_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "37bb64a1-2617-4599-86d2-ac2c14dc489e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 7, 17, 27],\n",
       "        [14, 32, 50],\n",
       "        [20, 46, 72]])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# to fix transpose issues, we use a transpose on one of the matrices\n",
    " \n",
    "torch.matmul(tensor_a, tensor_b.T)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b6d3da4-a7e0-41e0-8fc3-4c55b7de454c",
   "metadata": {},
   "source": [
    "### Finding min, max, mean, sum, etc (tensor aggregation)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71f06bee-16af-4eac-aa07-d8bbda88a649",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "9a0a57fa-e9dc-402f-b621-3c7b6ff02178",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2)\n",
      "tensor(7)\n",
      "tensor(4.5000)\n",
      "tensor(27)\n"
     ]
    }
   ],
   "source": [
    "# find the min\n",
    "print(torch.min(torch.min(tensor_a)))\n",
    "\n",
    "print(torch.max(tensor_a))\n",
    "\n",
    "print(torch.mean(tensor_a.type(torch.float32))) #can only work on dtype <= torch.float32\n",
    "\n",
    "print(torch.sum(tensor_a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "38af957b-f764-4e75-a73e-1b9b86056573",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(5)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# argmin and argmax, are methods used to get the index position of the max or min value in a tensor\n",
    "\n",
    "tensor_a.argmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "c0aae4f6-7338-4581-b46d-e67e35fa8472",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(7)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_a.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "be02e7c2-4bac-4819-aee3-5894019f6e89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[3, 2],\n",
       "        [4, 5],\n",
       "        [6, 7]])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_a"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ed1365c-1e36-4ac9-9e95-18567cc4d83b",
   "metadata": {},
   "source": [
    "## Reshaping, stacking, squeezing, and unsqueezing tensors\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
