{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "59c7ffb2-c703-4479-9c35-bae4a1b9c5d2",
   "metadata": {},
   "source": [
    "## 01. PyTorch Workflow Fundamentals\n",
    "The essence of machine learning and deep learning is to take some data from the past, build an algorithm (like a neural network) to discover patterns in it and use the discoverd patterns to predict the future.\n",
    "\n",
    "There are many ways to do this and many new ways are being discovered all the time.\n",
    "\n",
    "But let's start small.\n",
    "\n",
    "How about we start with a straight line?\n",
    "\n",
    "And we see if we can build a PyTorch model that learns the pattern of the straight line and matches it.\n",
    "\n",
    "What we're going to cover\n",
    "In this module we're going to cover a standard PyTorch workflow (it can be chopped and changed as necessary but it covers the main outline of steps).\n",
    "\n",
    "<img src=\"pix/01_a_pytorch_workflow.png\" alt=\"01_a_pytorch_workflow.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27ee8a0c-4ae0-46a2-b593-93258ed981d9",
   "metadata": {},
   "source": [
    "For now, we'll use this workflow to predict a simple straight line but the workflow steps can be repeated and changed depending on the problem you're working on.\n",
    "\n",
    "Specifically, we're going to cover:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a253cdc-d587-47b2-95b8-00c50fe3f9ae",
   "metadata": {},
   "source": [
    "| Topic | Contents |\n",
    "| :--------------------- | :-------------------------------------------------------------- |\n",
    "| 1. Getting data ready | Data can be almost anything but to get started we are going to create a simple straight line |\n",
    "| 2. Building a model | Here we'll create a model to learn patterns in the data, we'll also choose a loss function, optimizer and build a training loop. |\n",
    "| 3. Fitting the model to the data (training) | We have got data and a model, now let's let the model (try to) find patterns in the training data. |\n",
    "| 4. Making predictions and evaluating a model (Inference) | Our MOdel's found patterns in the data, let's compare its findings to the actual (testing) data. |\n",
    "| 5. Saving and loading a model | You may want to use your model elsewhere, or comeback to it later, here we'll cover that. |\n",
    "| 6. Putting it all together | let's take all of the above and combine it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01793d4d-d197-4fc3-ab23-0c7b776b5b3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import math\n",
    "# this ensures that the current MacOS version is at least 12.3+\n",
    "print(torch.backends.mps.is_available())\n",
    "# this ensures that the current current PyTorch installation was built with MPS activated.\n",
    "print(torch.backends.mps.is_built())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b299d7c2-7bf4-4f2f-abc7-3df105a5716d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.0.1'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# check pytorch version\n",
    "torch.__version__\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8c00df46-7e5d-4091-b261-86b493b876f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps\n"
     ]
    }
   ],
   "source": [
    "# set device to mps\n",
    "\n",
    "device= 'mps' if torch.backends.mps.is_available() else 'cpu'\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "850ad217-db7c-46e1-a444-bd968c941fd6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0.0000],\n",
       "         [0.0200],\n",
       "         [0.0400],\n",
       "         [0.0600],\n",
       "         [0.0800]]),\n",
       " tensor([[0.3000],\n",
       "         [0.3140],\n",
       "         [0.3280],\n",
       "         [0.3420],\n",
       "         [0.3560]]))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create weights and bias\n",
    "weight= 0.7\n",
    "bias= 0.3\n",
    "\n",
    "# create range values\n",
    "START= 0\n",
    "STOP= 1\n",
    "STEP= 0.02\n",
    "\n",
    "# create X and y (features and label)\n",
    "X= torch.arange(START, STOP, STEP).unsqueeze(dim=1)\n",
    "y= weight * X + bias\n",
    "\n",
    "X[:5], y[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bba53892-6258-4141-b618-09dc7b1fe641",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40, 40, 10, 10)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# split the data in train and test sets\n",
    "\n",
    "train_split= int(0.8*len(X))\n",
    "\n",
    "X_train= X[:train_split]\n",
    "X_test= X[train_split:]\n",
    "\n",
    "y_train= y[:train_split]\n",
    "y_test= y[train_split:]\n",
    "\n",
    "len(X_train), len(y_train), len(X_test), len(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0a7a01f2-ec1f-4b1c-8a41-ce3d581ca890",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(LinearRegressionModelV2(\n",
       "   (linear_layer): Linear(in_features=1, out_features=1, bias=True)\n",
       " ),\n",
       " OrderedDict([('linear_layer.weight', tensor([[0.7645]])),\n",
       "              ('linear_layer.bias', tensor([0.8300]))]))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Building a torch model\n",
    "\n",
    "# subclass nn.module to build our model\n",
    "class LinearRegressionModelV2(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        # use nn.linear to create model parameters\n",
    "        self.linear_layer= nn.Linear(in_features=1, \n",
    "                                    out_features=1)\n",
    "\n",
    "    # define the forward computation (input data x flows through the nn.Linear\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        return self.linear_layer(x)\n",
    "\n",
    "\n",
    "# set the manual random seed when creating the model\n",
    "torch.manual_seed(42)\n",
    "model_1= LinearRegressionModelV2()\n",
    "model_1, model_1.state_dict()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "75854cd4-ecf0-4ac5-86bd-afc1bfd45dc7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check model device\n",
    "next(model_1.parameters()).device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4bd55abc-eb8c-47e7-b049-f24a7980c146",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='mps', index=0)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set model to GPU if available\n",
    "model_1.to(device)\n",
    "next(model_1.parameters()).device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8757911-aeff-4278-93f3-69bd08efb50b",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "12bc9e6d-0a9d-42a3-bd7b-a35ac7a92af5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a loss function\n",
    "loss_fn= nn.L1Loss()\n",
    "\n",
    "# create an optimizer\n",
    "optimizer= torch.optim.SGD(params= model_1.parameters(),\n",
    "                           lr= 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6e356b6b-1142-41fe-b1ad-b3930dc52738",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 | train loss: 0.05761389806866646 | test loss: 0.004697275348007679\n",
      "Epoch: 100 | train loss: 0.004472536034882069 | test loss: 0.005817919969558716\n",
      "Epoch: 200 | train loss: 0.004472536034882069 | test loss: 0.005817919969558716\n",
      "Epoch: 300 | train loss: 0.004472536034882069 | test loss: 0.005817919969558716\n",
      "Epoch: 400 | train loss: 0.004472536034882069 | test loss: 0.005817919969558716\n",
      "Epoch: 500 | train loss: 0.004472536034882069 | test loss: 0.005817919969558716\n",
      "Epoch: 600 | train loss: 0.004472536034882069 | test loss: 0.005817919969558716\n",
      "Epoch: 700 | train loss: 0.004472536034882069 | test loss: 0.005817919969558716\n",
      "Epoch: 800 | train loss: 0.004472536034882069 | test loss: 0.005817919969558716\n",
      "Epoch: 900 | train loss: 0.004472536034882069 | test loss: 0.005817919969558716\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "\n",
    "# set the number of epochs\n",
    "epochs= 1000\n",
    "\n",
    "# put all data on GPU, an error will occur if this is not done\n",
    "X_train.to(device)\n",
    "X_test.to(device)\n",
    "y_train.to(device)\n",
    "y_test.to(device)\n",
    "\n",
    "\n",
    "# begin the training loop\n",
    "for epochs in range(epochs):\n",
    "    # training\n",
    "    model_1.train()\n",
    "\n",
    "    # forward pass\n",
    "    y_pred= model_1(X_train)\n",
    "\n",
    "    # calculate the loss;\n",
    "    loss= loss_fn(y_pred, y_train)\n",
    "\n",
    "    # zero grad optimizer\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # 4. loss backwards\n",
    "    loss.backward()\n",
    "\n",
    "    #step the optimizer\n",
    "    optimizer.step()\n",
    "\n",
    "    # testing\n",
    "    # forward pass\n",
    "    with torch.inference_mode():\n",
    "        test_pred= model_1(X_test)\n",
    "\n",
    "        # calculate the loss\n",
    "        test_loss= loss_fn(test_pred, y_test)\n",
    "\n",
    "    if epochs% 100 == 0:\n",
    "        print(f\"Epoch: {epochs} | train loss: {loss} | test loss: {test_loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "117a4ed6-e537-49ce-8ec0-ed9de89b5ff1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(LinearRegressionModelV2(\n",
       "   (linear_layer): Linear(in_features=1, out_features=1, bias=True)\n",
       " ),\n",
       " OrderedDict([('linear_layer.weight', tensor([[0.6936]])),\n",
       "              ('linear_layer.bias', tensor([0.2980]))]))"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_1, model_1.state_dict()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3c8468fc-2ad8-412c-a67c-d0f1a25df4fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "from sklearn.datasets import make_circles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "84fd3bf5-c92a-4d36-b9bc-c712adf57375",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pytorch-ignite\n",
      "  Downloading pytorch_ignite-0.4.12-py3-none-any.whl (266 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m266.8/266.8 kB\u001b[0m \u001b[31m592.3 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: torch<3,>=1.3 in /Users/data_lord/miniforge3/envs/torch_gpu/lib/python3.8/site-packages (from pytorch-ignite) (2.0.1)\n",
      "Requirement already satisfied: packaging in /Users/data_lord/miniforge3/envs/torch_gpu/lib/python3.8/site-packages (from pytorch-ignite) (23.1)\n",
      "Requirement already satisfied: filelock in /Users/data_lord/miniforge3/envs/torch_gpu/lib/python3.8/site-packages (from torch<3,>=1.3->pytorch-ignite) (3.12.2)\n",
      "Requirement already satisfied: typing-extensions in /Users/data_lord/miniforge3/envs/torch_gpu/lib/python3.8/site-packages (from torch<3,>=1.3->pytorch-ignite) (4.7.1)\n",
      "Requirement already satisfied: sympy in /Users/data_lord/miniforge3/envs/torch_gpu/lib/python3.8/site-packages (from torch<3,>=1.3->pytorch-ignite) (1.12)\n",
      "Requirement already satisfied: networkx in /Users/data_lord/miniforge3/envs/torch_gpu/lib/python3.8/site-packages (from torch<3,>=1.3->pytorch-ignite) (3.1)\n",
      "Requirement already satisfied: jinja2 in /Users/data_lord/miniforge3/envs/torch_gpu/lib/python3.8/site-packages (from torch<3,>=1.3->pytorch-ignite) (3.1.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/data_lord/miniforge3/envs/torch_gpu/lib/python3.8/site-packages (from jinja2->torch<3,>=1.3->pytorch-ignite) (2.1.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in /Users/data_lord/miniforge3/envs/torch_gpu/lib/python3.8/site-packages (from sympy->torch<3,>=1.3->pytorch-ignite) (1.3.0)\n",
      "Installing collected packages: pytorch-ignite\n",
      "Successfully installed pytorch-ignite-0.4.12\n"
     ]
    }
   ],
   "source": [
    "!pip install pytorch-ignite\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24bd7316-5932-4bfd-b164-fd19801abbd8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
